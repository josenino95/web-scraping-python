<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Web Scraping with Python: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css">
<script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Lesson Description" src="assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/aio.html';">Instructor View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Web Scraping with Python
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Web Scraping with Python
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Web Scraping with Python
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/aio.html">Instructor View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="hello-scraping.html">1. Hello-Scraping</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="a-real-website.html">2. Scraping a real website</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="dynamic-websites.html">3. Dynamic websites</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-hello-scraping"><p>Content from <a href="hello-scraping.html">Hello-Scraping</a></p>
<hr>
<p>Last updated on 2024-11-04 |

        <a href="https://github.com/josenino95/web-scraping-python/edit/main/episodes/hello-scraping.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is behind a website and how can I extract its information?</li>
<li>What is there to consider before I do web scraping?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Identify the structure and basic components of an HTML
document.</li>
<li>Use BeautifulSoup to locate elements, tags, attributes and text in
an HTML document.</li>
<li>Understand the situations in which web scraping is not suitable for
obtaining the desired data.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>This is part two of an Introduction to Web Scraping workshop we
offered on February 2024. You can refer to those <a href="https://ucsbcarpentry.github.io/2024-02-27-ucsb-webscraping/" class="external-link">workshop
materials</a> to have a more gentle introduction to scraping using XPath
and the <code>Scraper</code> Chrome extension.</p>
<p>We’ll refresh some of the concepts covered there to have a practical
understanding of how content/data is structured in a website. For that
purpose, we’ll see what Hypertext Markup Language (HTML) is and how it
structures and formats the content using <code>tags</code>. From there,
we’ll use the BeautifulSoup library to parse the HTML content so we can
easily search and access elements of the website we are interested in.
Starting from basic examples, we’ll move to scrape more complex,
real-life websites.</p>
</section><section><h2 class="section-heading" id="html-quick-overview">HTML quick overview<a class="anchor" aria-label="anchor" href="#html-quick-overview"></a>
</h2>
<hr class="half-width">
<p>All websites have a Hypertext Markup Language (HTML) document behind
them. The following text is HTML for a very simple website, with only
three sentences. If you look at it, can you imagine how that website
looks?</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">HTML<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode html" tabindex="0"><code class="sourceCode html"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="dt">&lt;!DOCTYPE</span> html<span class="dt">&gt;</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">html</span><span class="dt">&gt;</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">head</span><span class="dt">&gt;</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">title</span><span class="dt">&gt;</span>Sample web page<span class="dt">&lt;/</span><span class="kw">title</span><span class="dt">&gt;</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">head</span><span class="dt">&gt;</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">body</span><span class="dt">&gt;</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">h1</span><span class="dt">&gt;</span>h1 Header #1<span class="dt">&lt;/</span><span class="kw">h1</span><span class="dt">&gt;</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">p</span><span class="dt">&gt;</span>This is a paragraph tag<span class="dt">&lt;/</span><span class="kw">p</span><span class="dt">&gt;</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">h2</span><span class="dt">&gt;</span>h2 Sub-header<span class="dt">&lt;/</span><span class="kw">h2</span><span class="dt">&gt;</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">p</span><span class="dt">&gt;</span>A new paragraph, now in the <span class="dt">&lt;</span><span class="kw">b</span><span class="dt">&gt;</span>sub-header<span class="dt">&lt;/</span><span class="kw">b</span><span class="dt">&gt;&lt;/</span><span class="kw">p</span><span class="dt">&gt;</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">h1</span><span class="dt">&gt;</span>h1 Header #2<span class="dt">&lt;/</span><span class="kw">h1</span><span class="dt">&gt;</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">p</span><span class="dt">&gt;</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>This other paragraph has two hyperlinks,</span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>one to <span class="dt">&lt;</span><span class="kw">a</span><span class="ot"> href</span><span class="op">=</span><span class="st">"https://carpentries.org/"</span><span class="dt">&gt;</span>The Carpentries homepage<span class="dt">&lt;/</span><span class="kw">a</span><span class="dt">&gt;</span>,</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>and another to the</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">a</span><span class="ot"> href</span><span class="op">=</span><span class="st">"https://carpentries.org/past_workshops/"</span><span class="dt">&gt;</span>past workshops<span class="dt">&lt;/</span><span class="kw">a</span><span class="dt">&gt;</span> page.</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">p</span><span class="dt">&gt;</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">body</span><span class="dt">&gt;</span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">html</span><span class="dt">&gt;</span></span></code></pre>
</div>
<p>Well, if you put that text in a file with a .html extension, the job
of your web browser when opening the file will be to interpret that
(markup) language and display a nicely formatted website.</p>
<figure><img src="fig/simple_website.PNG" alt="Screenshot of a simple website with the previews HTML" class="figure mx-auto d-block"></figure><p>An HTML document is composed of <strong>elements</strong>, which can
be identified by <strong>tags</strong> written inside angle brackets
(<code>&lt;</code> and <code>&gt;</code>). For example, the HTML root
element, which delimits the beginning and end of an HTML document, is
identified by the <code>&lt;html&gt;</code> tag.</p>
<p>Most elements have both a opening and a closing tag, determining the
span of the element. In the previous simple website, we see a head
element that goes from the opening tag <code>&lt;head&gt;</code> up to
the closing tag <code>&lt;/head&gt;</code>. Given than an element can be
inside another element, an HTML document has a tree structure, where
every element is a node that can contain child nodes, like the following
image shows.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/5/5a/DOM-model.svg" alt="Screenshot of a simple website with the previews HTML" class="figure mx-auto d-block"><div class="figcaption">The Document Object Model (DOM) that represents
an HTML document with a tree structure. Source: Wikipedia. Author:
Birger Eriksson</div>
</figure><p>Finally, we can define or modify the behavior, appeareance, or
functionality of an element by using <strong>attributes</strong>.
Attributes are inside the opening tag, and consist of a name and a
value, formatted as <code>name="value"</code>. For example, in the
previous simple website, we added a hyperlink with the
<code>&lt;a&gt;...&lt;/a&gt;</code> tags, but to set the destination URL
we used the <code>href</code> attribute by writing in the opening tag
<code>a href="https://carpentries.org/past_workshops/"</code>.</p>
<p>Here is a non-exhaustive list of elements you’ll find in HTML and
their purpose:</p>
<ul>
<li>
<code>&lt;hmtl&gt;...&lt;/html&gt;</code> The root element, which
contains the entirety of the document.</li>
<li>
<code>&lt;head&gt;...&lt;/head&gt;</code> Contains metadata, for
example, the title that the web browser displays.</li>
<li>
<code>&lt;body&gt;...&lt;/body&gt;</code> The content that is going
to be displayed.</li>
<li>
<code>&lt;h1&gt;...&lt;/h1&gt;, &lt;h2&gt;...&lt;/h2&gt;, &lt;h3&gt;...&lt;/h3&gt;</code>
Defines headers of level 1, 2, 3, etc.</li>
<li>
<code>&lt;p&gt;...&lt;/p&gt;</code> A paragraph.</li>
<li>
<code>&lt;a href=""&gt;...&lt;/a&gt;</code> Creates a hyperlink, and
we provide the destination URL with the <code>href</code>
attribute.</li>
<li>
<code>&lt;img src="" alt=""&gt;</code> Embedds an image, giving a
source to the image with the <code>src</code> attribute and specifying
alternate text with <code>alt</code>.</li>
<li>
<code>&lt;table&gt;...&lt;/table&gt;, &lt;th&gt;...&lt;/th&gt;, &lt;tr&gt;...&lt;/tr&gt;, &lt;td&gt;...&lt;/td&gt;</code>
Defines a table, that as children will have a header (defined inside
<code>th</code>), rows (defined inside <code>tr</code>), and a cell
inside a row (as <code>td</code>).</li>
<li>
<code>&lt;div&gt;...&lt;/div&gt;</code> Is used to group sections of
HTML content.</li>
<li>
<code>&lt;script&gt;...&lt;/script&gt;</code> Embeds or references
JavaScript code.</li>
</ul>
<p>In the previous list we’ve described some attributes specific for the
hyperlink elements (<code>&lt;a&gt;</code>) and the image elements
(<code>&lt;img&gt;</code>), but there are a few other global attributes
that most HTML elements can have and are useful to identify specific
elements when doing web scraping:</p>
<ul>
<li>
<code>id=""</code> Assigns a unique identifier to an element, which
cannot be repeated in the entire HTML document</li>
<li>
<code>title=""</code> Provides extra information, displayed as a
tooltip when the user hovers over the element.</li>
<li>
<code>class=""</code> Is used to apply a similar styling to multiple
elements at once.</li>
</ul>
<p>To summarize, an <strong>element</strong> is identified by
<strong>tags</strong>, and we can assign properties to an element by
using <strong>attributes</strong>. Knowing this about HTML will make our
lifes easier when trying to get some specific data from a website.</p>
</section><section><h2 class="section-heading" id="parsing-html-with-beautifulsoup">Parsing HTML with BeautifulSoup<a class="anchor" aria-label="anchor" href="#parsing-html-with-beautifulsoup"></a>
</h2>
<hr class="half-width">
<p>Now that we know how a website is structured, we can start extracting
information from it. The BeautifulSoup package is our main tool for that
task, as it will parse the HTML so we can search and access the elements
of interest in a programmatic way.</p>
<p>To see how this package works, we’ll use the simple website example
we showed before. As our first step, we will load the BeautifulSoup
package, along with Pandas.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code></pre>
</div>
<p>Let’s get the HTML content inside a string variable called
<code>example_html</code></p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>example_html <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="st">&lt;!DOCTYPE html&gt;</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="st">&lt;html&gt;</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="st">&lt;head&gt;</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="st">&lt;title&gt;Sample web page&lt;/title&gt;</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="st">&lt;/head&gt;</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="st">&lt;body&gt;</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="st">&lt;h1&gt;h1 Header #1&lt;/h1&gt;</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="st">&lt;p&gt;This is a paragraph tag&lt;/p&gt;</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="st">&lt;h2&gt;h2 Sub-header&lt;/h2&gt;</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="st">&lt;p&gt;A new paragraph, now in the &lt;b&gt;sub-header&lt;/b&gt;&lt;/p&gt;</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="st">&lt;h1&gt;h1 Header #2&lt;/h1&gt;</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="st">&lt;p&gt;</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="st">This other paragraph has two hyperlinks,</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="st">one to &lt;a href="https://carpentries.org/"&gt;The Carpentries homepage&lt;/a&gt;,</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="st">and another to the</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="st">&lt;a href="https://carpentries.org/past_workshops/"&gt;past workshops&lt;/a&gt; page.</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="st">&lt;/p&gt;</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="st">&lt;/body&gt;</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a><span class="st">&lt;/html&gt;</span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="st">"""</span></span></code></pre>
</div>
<p>We parse this HTML using the <code>BeautifulSoup()</code> function we
imported, specifying that we want to use the <code>html.parser</code>.
This object will represent the document as a nested data structure,
similar to a tree as we mentioned before. If we use the
<code>.prettify()</code> method on this object, we can see the nested
structure, as inner elements will be indented to the right.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(example_html, <span class="st">'html.parser'</span>)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="bu">print</span>(soup.prettify())</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
 &lt;head&gt;
  &lt;title&gt;
   Sample web page
  &lt;/title&gt;
 &lt;/head&gt;
 &lt;body&gt;
  &lt;h1&gt;
   h1 Header #1
  &lt;/h1&gt;
  &lt;p&gt;
   This is a paragraph tag
  &lt;/p&gt;
  &lt;h2&gt;
   h2 Sub-header
  &lt;/h2&gt;
  &lt;p&gt;
   A new paragraph, now in the
   &lt;b&gt;
    sub-header
   &lt;/b&gt;
  &lt;/p&gt;
  &lt;h1&gt;
   h1 Header #2
  &lt;/h1&gt;
  &lt;p&gt;
   This other paragraph has two  hyperlinks, one to
   &lt;a href="https://carpentries.org/"&gt;
    The Carpentries homepage
   &lt;/a&gt;
   , and another to the
   &lt;a href="https://carpentries.org/past_workshops/"&gt;
    past workshops
   &lt;/a&gt;
   .
  &lt;/p&gt;
 &lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
<p>Now that our <code>soup</code> variable holds the parsed document, we
can use the <code>.find()</code> and <code>.find_all()</code> methods.
<code>.find()</code> will search the tag that we specify, and return the
entire element, including the starting and closing tags. If there are
multiple elements with the same tag, <code>.find()</code> will only
return the first one. If you want to return all the elements that match
your search, you’d want to use <code>.find_all()</code> instead, which
will return them in a list. Additionally, to return the text contained
in a given element and all its children, you’d use
<code>.get_text()</code>. Below you can see how all these commands play
out in our simple website example.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"1."</span>, soup.find(<span class="st">'title'</span>))</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"2."</span>, soup.find(<span class="st">'title'</span>).get_text())</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"3."</span>, soup.find(<span class="st">'h1'</span>).get_text())</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"4."</span>, soup.find_all(<span class="st">'h1'</span>))</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"5."</span>, soup.find_all(<span class="st">'a'</span>))</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"6."</span>, soup.get_text())</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>1. &lt;title&gt;Sample web page&lt;/title&gt;
2. Sample web page
3. h1 Header #1
4. [&lt;h1&gt;h1 Header #1&lt;/h1&gt;, &lt;h1&gt;h1 Header #2&lt;/h1&gt;]
5. [&lt;a href="https://carpentries.org/"&gt;The Carpentries homepage&lt;/a&gt;, &lt;a href="https://carpentries.org/past_workshops/"&gt;past workshops&lt;/a&gt;]
6.



Sample web page


h1 Header #1
This is a paragraph tag
h2 Sub-header
A new paragraph, now in the sub-header
h1 Header #2
This other paragraph has two  hyperlinks, one to The Carpentries homepage, and another to the past workshops.



</code></pre>
</div>
<p>How would you extract all hyperlinks identified with
<code>&lt;a&gt;</code> tags? In our example, we see that there are only
two hyperlinks, and we could extract them in a list using the
<code>.find_all('a')</code> method.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>links <span class="op">=</span> soup.find_all(<span class="st">'a'</span>)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of hyperlinks found: "</span>, <span class="bu">len</span>(links))</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="bu">print</span>(links)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Number of hyperlinks found:  2
[&lt;a href="https://carpentries.org/"&gt;The Carpentries homepage&lt;/a&gt;, &lt;a href="https://carpentries.org/past_workshops/"&gt;past workshops&lt;/a&gt;]</code></pre>
</div>
<p>To access the value of a given attribute in an element, for example
the value of the <code>href</code> attribute in
<code>&lt;a href=""&gt;</code>, we would use square brackets and the
name of the attribute (<code>['href']</code>), just like how in a Python
dictionary we would access the value using the respective key. Let’s
make a loop that prints only the URL for each hyperlink we have in our
example.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> links:</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>    <span class="bu">print</span>(item[<span class="st">'href'</span>])</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>https://carpentries.org/
https://carpentries.org/past_workshops/</code></pre>
</div>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Create a Python dictionary that has the following three items,
containing information about the <strong>first</strong> hyperlink in the
HTML of our example.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>first_link <span class="op">=</span> {</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>   <span class="st">'element'</span>: the complete hyperlink element,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>   <span class="st">'url'</span>: the destination url of the hyperlink,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>   <span class="st">'text'</span>: the text that the website displays <span class="im">as</span> the hyperlink</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>}</span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>One way of completing the exercise is as follows.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>first_link <span class="op">=</span> {</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>   <span class="st">'element'</span>: <span class="bu">str</span>(soup.find(<span class="st">'a'</span>)),</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>   <span class="st">'url'</span>: soup.find(<span class="st">'a'</span>)[<span class="st">'href'</span>],</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>   <span class="st">'text'</span>: soup.find(<span class="st">'a'</span>).get_text()</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>}</span></code></pre>
</div>
<p>An alternate but similar way is to store the tag found for not
calling multiple times <code>soup.find('a')</code>, and also creating
first an empty dictionary and append to it the keys and values we want,
as this will be useful when we do this multiple times in a for loop.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>find_a <span class="op">=</span> soup.find(<span class="st">'a'</span>)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>first_link <span class="op">=</span> {}</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>first_link[<span class="st">'element'</span>] <span class="op">=</span> <span class="bu">str</span>(find_a)</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>first_link[<span class="st">'url'</span>] <span class="op">=</span> find_a[<span class="st">'href'</span>]</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>first_link[<span class="st">'text'</span>] <span class="op">=</span> find_a.get_text()</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<p>To finish this introduction on HTML and BeautifulSoup, let’s create
code for extracting in a structured way all the hyperlink elements,
their destination URL and the text displayed for link. For that, let’s
use the <code>links</code> variable that we created before as
<code>links = soup.find_all('a')</code>. We’ll loop over each hyperlink
element found, storing for each the three pieces of information we want
in a dictionary, and finally appending that dictionary to a list called
<code>list_of_dicts</code>. At the end we will have a list with two
elements, that we can transform to a Pandas dataframe.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>links <span class="op">=</span> soup.find_all(<span class="st">'a'</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>list_of_dicts <span class="op">=</span> []</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> links:</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>    dict_a <span class="op">=</span> {}</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>    dict_a[<span class="st">'element'</span>] <span class="op">=</span> <span class="bu">str</span>(item)</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>    dict_a[<span class="st">'url'</span>] <span class="op">=</span> item[<span class="st">'href'</span>]</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>    dict_a[<span class="st">'text'</span>] <span class="op">=</span> item.get_text()</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>    list_of_dicts.append(dict_a)</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>links_df <span class="op">=</span> pd.DataFrame(list_of_dicts)</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="bu">print</span>(links_df)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>                                             element  \
0  &lt;a href="https://carpentries.org/"&gt;The Carpent...
1  &lt;a href="https://carpentries.org/past_workshop...

                                       url                      text
0                 https://carpentries.org/  The Carpentries homepage
1  https://carpentries.org/past_workshops/            past workshops  </code></pre>
</div>
<p>You’ll find more useful information about the BeautifulSoup package
and how to use all its methods in the <a href="https://beautiful-soup-4.readthedocs.io/en/latest/" class="external-link">Beautiful Soup
Documentation website</a>.</p>
</section><section><h2 class="section-heading" id="the-rights-wrongs-and-legal-barriers-to-scraping">The rights, wrongs, and legal barriers to scraping<a class="anchor" aria-label="anchor" href="#the-rights-wrongs-and-legal-barriers-to-scraping"></a>
</h2>
<hr class="half-width">
<p>The internet is no longer what it used to be. Once an open and
boundless source of information, the web has become an invaluable pool
of data, widely used by companies to train machine learning and
generative AI models. Now, social media platforms and other website
owners have either recognized the potential for profit and licensed
their data or have become overwhelmed by bots crawling their sites and
straining their server resources.</p>
<p>For this reason, it’s now more common to see that a website’s Terms
of Service (TOS) explicitly prohibits web scraping. If we want to avoid
getting into trouble, we need to carefully check the TOS of your website
of interest as well as its ‘robots.txt’ file. You should be able to find
both using your preferred search engine, but you may directly go to the
latter by appending ‘/robots.txt’ at the root URL of the website
(e.g. for Facebook you’ll find it in ‘<a href="https://facebook.com/robots.txt" class="external-link uri">https://facebook.com/robots.txt</a>’, not in any other URL
like ‘<a href="https://facebook.com/user/robots.txt" class="external-link uri">https://facebook.com/user/robots.txt</a>’).</p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Visit <a href="https://www.facebook.com/terms.php" class="external-link">Facebook’s Terms
of Service</a> and its <a href="https://facebook.com/robots.txt" class="external-link">robots.txt file</a>. What do they
say about web scraping or collecting data using automated means? Compare
it to <a href="https://redditinc.com/policies/user-agreement-september-25-2023" class="external-link">Reddit’s
TOS</a> and <a href="https://www.reddit.com/robots.txt" class="external-link">Reddit’s
robots.txt</a>.</p>
</div>
</div>
</div>
<p>Besides checking the website’s policies, you should also be aware of
the legislation applicable to your location regarding copyright and data
privacy laws. If you plan to start harvesting a large amount of data for
research or commercial purposes, you should probably seek legal advice
first. If you work in a university, chances are it has a copyright
office that will help you sort out the legal aspects of your project.
The university library is often the best place to start looking for help
on copyright.</p>
<p>To conclude, here is a brief code of conduct you should consider when
doing web scraping:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Ask nicely if you can access the data in another
way</strong>. If your project requires data from a particular
organisation, you can try asking them directly if they could provide you
what you are looking for, or check if they have an API to access the
data. With some luck, they will have the primary data that they used on
their website in a structured format, saving you the trouble.</li>
<li>
<strong>Don’t download copies of documents that are clearly not
public</strong>. For example, academic journal publishers often have
very strict rules about what you can and what you cannot do with their
databases. Mass downloading article PDFs is probably prohibited and can
put you (or at the very least your friendly university librarian) in
trouble. If your project requires local copies of documents (e.g. for
text mining projects), special agreements can be reached with the
publisher. The library is a good place to start investigating something
like that.</li>
<li>
<strong>Check your local legislation</strong>. For example, certain
countries have laws protecting personal information such as email
addresses and phone numbers. Scraping such information, even from
publicly avaialable web sites, can be illegal (e.g. in Australia).</li>
<li>
<strong>Don’t share downloaded content illegally</strong>. Scraping
for personal purposes is usually OK, even if it is copyrighted
information, as it could fall under the fair use provision of the
intellectual property legislation. However, sharing data for which you
don’t hold the right to share is illegal.</li>
<li>
<strong>Share what you can</strong>. If the data you scraped is in
the public domain or you got permission to share it, then put it out
there for other people to reuse it (e.g. on datahub.io). If you wrote a
web scraper to access it, share its code (e.g. on GitHub) so that others
can benefit from it.</li>
<li>
<strong>Publish your own data in a reusable way</strong>. Don’t
force others to write their own scrapers to get at your data. Use open
and software-agnostic formats (e.g. JSON, XML), provide metadata (data
about your data: where it came from, what it represents, how to use it,
etc.) and make sure it can be indexed by search engines so that people
can find it.</li>
<li>
<strong>Don’t break the Internet</strong>. Not all web sites are
designed to withstand thousands of requests per second. If you are
writing a recursive scraper (i.e. that follows hyperlinks), test it on a
smaller dataset first to make sure it does what it is supposed to do.
Adjust the settings of your scraper to allow for a delay between
requests. More on this topic in the next episode.</li>
</ol>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Every website has an HTML document behind it that gives a structure
to its content.</li>
<li>An HTML is composed of elements, which usually have a opening
<code>&lt;tag&gt;</code> and a closing <code>&lt;/tag&gt;</code>.</li>
<li>Elements can have different properties, assigned by attributes in
the form of <code>&lt;tag attribute_name="value"&gt;</code>.</li>
<li>We can parse any HTML document with <code>BeautifulSoup()</code> and
find elements using the <code>.find()</code> and
<code>.find_all()</code> methods.</li>
<li>We can access the text of an element using the
<code>.get_text()</code> method and the attribute values as we do with
Python dictionaries (<code>element["attribute_name"]</code>).</li>
<li>We must be careful to not tresspass the Terms of Service (TOS) of
the website we are scraping.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-a-real-website"><p>Content from <a href="a-real-website.html">Scraping a real website</a></p>
<hr>
<p>Last updated on 2024-11-04 |

        <a href="https://github.com/josenino95/web-scraping-python/edit/main/episodes/a-real-website.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can I get the data and information from a real website?</li>
<li>How can I start automating my web scraping tasks?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Use the <code>requests</code> package to get the HTML document
behind a website.</li>
<li>Navigate the tree structure behind an HTML document to extract the
information we need.</li>
<li>Know how to avoid being blocked by sending too much requests to a
website.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="requests-the-website-html">“Requests” the website HTML<a class="anchor" aria-label="anchor" href="#requests-the-website-html"></a>
</h2>
<hr class="half-width">
<p>In the previous episode we used a simple HTML document, not an actual
website. Now that we move to more real, complex escenario, we need to
add another package to our toolbox, the <code>requests</code> package.
For the purpose of this web scraping lesson, we will only use
<code>requests</code> to get the HTML behind a website. However, there’s
a lot of extra functionality that we are not covering but you can find
in the <a href="https://requests.readthedocs.io/en/latest/" class="external-link">Requests
package documentation</a>.</p>
<p>We’ll be scraping The Carpentries website, <a href="https://carpentries.org/" class="external-link">https://carpentries.org/</a>, and
specifically, the list of upcoming and past workshop you can find at the
bottom. For that, first we’ll load the <code>requests</code> package and
then use the code <code>.get().text</code> to store the HTML document of
the website. Furthermore, to simplify our navigation through the HTML
document, we will use the <a href="https://docs.python.org/3/howto/regex.html" class="external-link">Regular
Expressions</a> <code>re</code> module to remove all new line characters
(“”) and their surrounding whitespaces. You can think of removing new
lines as a preprocessing or cleaning step, but in this lesson we won’t
be explaining the intricacies of regular expressions. For that, you can
refer to this introductory explanation on the <a href="https://librarycarpentry.org/lc-data-intro/01-regular-expressions.html" class="external-link">Library
Carpentry</a>.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>url <span class="op">=</span> <span class="st">'https://carpentries.org/'</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>req <span class="op">=</span> requests.get(url).text</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>cleaned_req <span class="op">=</span> re.sub(<span class="vs">r'\s*\n\s*'</span>, <span class="st">''</span>, req).strip()</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="bu">print</span>(cleaned_req[<span class="dv">0</span>:<span class="dv">1000</span>])</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>&lt;!doctype html&gt;&lt;html class="no-js" lang="en"&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;&lt;title&gt;The Carpentries&lt;/title&gt;&lt;link rel="stylesheet" type="text/css" href="https://carpentries.org/assets/css/styles_feeling_responsive.css"&gt;&lt;script src="https://carpentries.org/assets/js/modernizr.min.js"&gt;&lt;/script&gt;&lt;!-- matomo --&gt;&lt;script src="https://carpentries.org/assets/js/matomo-analytics.js"&gt;&lt;/script&gt;&lt;link href="https://fonts.googleapis.com/css?family=Lato:400,400i,700,700i|Roboto:400,400i,700,700i&amp;display=swap" rel="stylesheet"&gt;&lt;!-- Search Engine Optimization --&gt;&lt;meta name="description" content="The Carpentries is a fiscally sponsored project of Community Initiatives, a registered 501(c)3 non-profit organisation based in California, USA. We are a global community teaching foundational computational and data science skills to researchers in academia, industry and government."&gt;&lt;link rel="canonical" href="https://carpentries.org/index.html"&gt;&lt;</code></pre>
</div>
<p>We truncated to print only the first 1000 characters of the document,
as it is too long, but we can see it is HTML and has some elements we
didn’t see in the example of the previous episode, like those identified
with the <code>&lt;meta&gt;</code>, <code>&lt;link&gt;</code> and
<code>&lt;script&gt;</code> tags.</p>
<p>There’s another way to see the HTML document behind a website,
directly from your web browser. Using Google Chrome, you can right-click
in any part of the website (on a Mac, press and hold the Control key in
your keyboard while you click), and from the pop-up menu, click ‘View
page source’, as the next image shows. If the ‘View page source’ option
didn’t appear for you, try clicking in another part of the website. A
new tab will open with the HTML document for the website you were
in.</p>
<figure><img src="fig/view_page_source.png" alt="A screenshot of The Carpentries homepage in the Google Chrome web browser, showing how to View page source" class="figure mx-auto d-block"></figure><p>In the HTML page source on your browser you can scroll down and look
for the second-level header (<code>&lt;h2&gt;</code>) with the text
“Upcoming Carpentries Workshops”. Or more easily, you can use the Find
Bar (Ctrl + F on Windows and Command + F on Mac) to search for “Upcoming
Carpentries Workshops”. Just right down of that header we have the table
element we are interested in, which starts with the opening tag
<code>&lt;table class="table table-striped" style="width: 100%;"&gt;</code>.
Inside that element we see nested different elements familiar for a
table, the rows (<code>&lt;tr&gt;</code>) and the cells for each row
(<code>&lt;td&gt;</code>), and additionally the image
(<code>&lt;img&gt;</code>) and hyperlink (<code>&lt;a&gt;</code>)
elements.</p>
</section><section><h2 class="section-heading" id="finding-the-information-we-want">Finding the information we want<a class="anchor" aria-label="anchor" href="#finding-the-information-we-want"></a>
</h2>
<hr class="half-width">
<p>Now, going back to our coding, we left off on getting the HTML behind
the website using <code>requests</code>, and stored it on the variable
called <code>req</code>. From here we can proceed with BeautifulSoup as
we learned in the previous episode, using the
<code>BeautifulSoup()</code> function to parse our HTML, as the
following code block shows. With the parsed document, we can use the
<code>.find()</code> or <code>find_all()</code> methods to find the
table element.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(cleaned_req, <span class="st">'html.parser'</span>)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>tables_by_tag <span class="op">=</span> soup.find_all(<span class="st">'table'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of table elements found: "</span>, <span class="bu">len</span>(tables_by_tag))</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Printing only the first 1000 characters of the table element: </span><span class="ch">\n</span><span class="st">"</span>, <span class="bu">str</span>(tables_by_tag[<span class="dv">0</span>])[<span class="dv">0</span>:<span class="dv">1000</span>])</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Number of table elements found:  1
Printing only the first 1000 characters of the table element:
 &lt;table class="table table-striped" style="width: 100%;"&gt;&lt;tr&gt;&lt;td&gt;&lt;img alt="swc logo" class="flags" height="24" src="https://carpentries.org/assets/img/logos/swc.svg" title="swc workshop" width="24"/&gt;&lt;/td&gt;&lt;td&gt;&lt;img alt="mx" class="flags" src="https://carpentries.org/assets/img/flags/24/mx.png" title="MX"&gt;&lt;img alt="globe image" class="flags" src="https://carpentries.org/assets/img/flags/24/w3.png" title="Online"&gt;&lt;a href="https://galn3x.github.io/-2024-10-28-Metagenomics-online/"&gt;Nodo Nacional de BioinformÃ¡tica UNAM&lt;/a&gt;&lt;br&gt;&lt;b&gt;Instructors:&lt;/b&gt; CÃ©sar Aguilar, Diana Oaxaca, Nelly Selem-Mojica&lt;br&gt;&lt;b&gt;Helpers:&lt;/b&gt; Andreas Chavez, JosÃ© Manuel Villalobos Escobedo, Aaron Espinosa Jaime, AndrÃ©s Arredondo, Mirna VÃ¡zquez Rosas-Landa, David Alberto GarcÃ­a-Estrada&lt;/br&gt;&lt;/br&gt;&lt;/img&gt;&lt;/img&gt;&lt;/td&gt;&lt;td&gt;Oct 28 - Oct 31, 2024&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;img alt="dc logo" class="flags" height="24" src="https://carpentries.org/assets/img/logos/dc.svg" title="dc workshop" width="24"/&gt;&lt;/td&gt;&lt;td&gt;&lt;img alt="de" class="flags" s</code></pre>
</div>
<p>From our output we see that there was only one table element in the
entire HTML, which corresponds to the table we are looking for. The
output you see in the previous code block will be different from what
you have in your computer, as the data in the upcoming workshops table
is continously updated.</p>
<p>Besides searching elements using tags, sometimes it will be useful to
search using attributes, like <code>id</code> or <code>class</code>. For
example, we can see the table element has a class attribute with two
values “table table-striped”, which identifies all possible elements
with similar styling. Therefore, we could have the same result than
before using the <code>class_</code> argument on the
<code>.find_all()</code> method as follows.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>tables_by_class <span class="op">=</span> soup.find_all(class_<span class="op">=</span><span class="st">"table table-striped"</span>)</span></code></pre>
</div>
<p>Now that we know there is only one table element, we can start
working with it directly by storing the first and only item in the
<code>tables_by_tag</code> result set into another variable, which we
will call just <code>workshops</code>. We can see that we moved from
working with a “ResultSet” object to a “Tag” object, which we can start
working with to extract information from each row and cell.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Before: "</span>, <span class="bu">type</span>(tables_by_tag))</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>workshops_table <span class="op">=</span> tables_by_tag[<span class="dv">0</span>]</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"After:"</span>, <span class="bu">type</span>(workshops_table))</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Element type:"</span>, workshops_table.name)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Before:  &lt;class 'bs4.element.ResultSet'&gt;
After: &lt;class 'bs4.element.Tag'&gt;
Element type: table</code></pre>
</div>
</section><section><h2 class="section-heading" id="navigating-the-tree">Navigating the tree<a class="anchor" aria-label="anchor" href="#navigating-the-tree"></a>
</h2>
<hr class="half-width">
<p>If we use the <code>prettify()</code> method on the
<code>workshops_table</code> variable, we see that this table element
has a nested tree structure. On the first level is the
<code>&lt;table&gt;</code> tag. Inside that, we have rows
<code>&lt;tr&gt;</code>, and inside rows we have table data cells
<code>&lt;td&gt;</code>. We can start to identify certain information we
may be interested in, for example:</p>
<ul>
<li>What type of workshop was it (‘swc’ for Software Carpentry, ‘dc’ for
Data Carpentry, ‘lc’ for Library Carpentry, and ‘cp’ for workshops based
on The Carpentries curriculum). We find this in the first
<code>&lt;td&gt;</code> tag, or said in a different way, in the first
cell of the row.</li>
<li>In what country was the workshop held. We can see the two-letter
country code in the second cell of the row.</li>
<li>The URL to the workshop website, which will contain additional
information. It is also contained in the second cell of the row, as the
<code>href</code> attribute of the <code>&lt;a&gt;</code> tag.</li>
<li>The institution that is hosting the workshop. Also in the second
<code>&lt;td&gt;</code>, in the text of the hyperlink
<code>&lt;a&gt;</code> tag.</li>
<li>The name of instructors and helpers involved in the workshop.</li>
<li>The dates of the workshop, on the third and final cell.</li>
</ul>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="bu">print</span>(workshops_table.prettify())</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>&lt;table class="table table-striped" style="width: 100%;"&gt;
 &lt;tr&gt;
  &lt;td&gt;
   &lt;img alt="swc logo" class="flags" height="24" src="https://carpentries.org/assets/img/logos/swc.svg" title="swc workshop" width="24"/&gt;
  &lt;/td&gt;
  &lt;td&gt;
   &lt;img alt="mx" class="flags" src="https://carpentries.org/assets/img/flags/24/mx.png" title="MX"&gt;
    &lt;img alt="globe image" class="flags" src="https://carpentries.org/assets/img/flags/24/w3.png" title="Online"&gt;
     &lt;a href="https://galn3x.github.io/-2024-10-28-Metagenomics-online/"&gt;
      Nodo Nacional de BioinformÃ¡tica UNAM
     &lt;/a&gt;
     &lt;br&gt;
      &lt;b&gt;
       Instructors:
      &lt;/b&gt;
      CÃ©sar Aguilar, Diana Oaxaca, Nelly Selem-Mojica
      &lt;br&gt;
       &lt;b&gt;
        Helpers:
       &lt;/b&gt;
       Andreas Chavez, JosÃ© Manuel Villalobos Escobedo, Aaron Espinosa Jaime, AndrÃ©s Arredondo, Mirna VÃ¡zquez Rosas-Landa, David Alberto GarcÃ­a-Estrada
      &lt;/br&gt;
     &lt;/br&gt;
    &lt;/img&gt;
   &lt;/img&gt;
  &lt;/td&gt;
  &lt;td&gt;
   Oct 28 - Oct 31, 2024
  &lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
  &lt;td&gt;
...
  &lt;/td&gt;
 &lt;/tr&gt;
&lt;/table&gt;</code></pre>
</div>
<p>To navigate in this HTML document tree we can use the following
properties of the “bs4.element.Tag” object: <code>.contents</code> (to
access direct children nodes), <code>.parent</code> (to access the
parent node), <code>.next_sibling</code>, and
<code>.previous_sibling</code> (to access the siblings of a node)
methods. For example, if we want to access the second row of the table,
which is the second child of the table element we could use the
following code.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># The second [1 in Python indexing] child of our table element</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>workshops_table.contents[<span class="dv">1</span>]</span></code></pre>
</div>
<p>If you go back to the ‘View page source’ of the website, you’ll
notice that the table element is nested inside a
<code>&lt;div class="medium-12 columns"&gt;</code> element, which means
this <code>&lt;div&gt;</code> is the parent of our
<code>&lt;table&gt;</code>. If we needed to, we could access this parent
by using <code>workshops_table.parent</code>.</p>
<p>Now imagine we had selected the second data cell of our fifth row
using <code>workshops_table.contents[4].contents[1]</code>, we could
access the third data cell using <code>.next_sibling()</code> or the
first data cell with <code>.previous_sibling()</code>.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># Access the fifth row, and from there, the second data cell</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>row5_cell2 <span class="op">=</span> workshops_table.contents[<span class="dv">4</span>].contents[<span class="dv">1</span>]</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co"># Access the third cell of the fifth row</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>row5_cell3 <span class="op">=</span> row5_cell2.next_sibling</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="co"># Access the first cell of the fifth row</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>row5_cell1 <span class="op">=</span> row5_cell2.previous_sibling</span></code></pre>
</div>
<p>Why do we bother to learn all this methods? Depending on you web
scraping use case, they might result useful in complex websites. Let’s
apply them to extract the information we want about the workshops, for
example, to see how many upcoming workshops there are, which corresponds
with the number of children the table element has</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>num_workshops <span class="op">=</span> <span class="bu">len</span>(workshops_table.contents)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of upcoming workshops listed: "</span>, num_workshops)</span></code></pre>
</div>
<p>Let’s work to extract data from only the first row, and later we can
use a loop to iterate over all the rows of the table.</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># Empty dictionary to hold the data</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>dict_w <span class="op">=</span> {}</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co"># First row of data</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>first_row <span class="op">=</span> workshops_table.contents[<span class="dv">0</span>]</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co"># To get to the first cell</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>first_cell <span class="op">=</span> first_row.contents[<span class="dv">0</span>]</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>second_cell <span class="op">=</span> first_cell.next_sibling</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>third_cell <span class="op">=</span> second_cell.next_sibling</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a><span class="co"># From the first cell, find the &lt;image&gt; tag and get the 'title' attribute, which contains the type of workshop</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>dict_w[<span class="st">'type'</span>] <span class="op">=</span> first_cell.find(<span class="st">'img'</span>)[<span class="st">'title'</span>]</span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a><span class="co"># In the second cell, get the country from the 'title' attribute of the &lt;image&gt; tag</span></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a>dict_w[<span class="st">'country'</span>] <span class="op">=</span> second_cell.find(<span class="st">'img'</span>)[<span class="st">'title'</span>]</span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a><span class="co"># Now the link to the workshop website is in the 'href' attribute of the &lt;a&gt; tag</span></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a>dict_w[<span class="st">'link'</span>] <span class="op">=</span> second_cell.find(<span class="st">'a'</span>)[<span class="st">'href'</span>]</span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a><span class="co"># The institution that hosts the workshop is the text inside that &lt;a&gt; tag</span></span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a>dict_w[<span class="st">'link'</span>] <span class="op">=</span> second_cell.find(<span class="st">'a'</span>).get_text()</span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a><span class="co"># Get all the text from the second cell</span></span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a>dict_w[<span class="st">'all_text'</span>] <span class="op">=</span> second_cell.get_text(strip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a><span class="co"># Get the dates from the third cell</span></span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a>dict_w[<span class="st">'date'</span>] <span class="op">=</span> third_cell.get_text(strip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a></span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a><span class="bu">print</span>(dict_w)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>{'type': 'swc workshop',
 'country': 'MX',
 'link': 'https://galn3x.github.io/-2024-10-28-Metagenomics-online/',
 'host': 'Nodo Nacional de BioinformÃ¡tica UNAM',
 'all_text': 'Nodo Nacional de BioinformÃ¡tica UNAMInstructors:CÃ©sar Aguilar, Diana Oaxaca, Nelly Selem-MojicaHelpers:Andreas Chavez, JosÃ© Manuel Villalobos Escobedo, Aaron Espinosa Jaime, AndrÃ©s Arredondo, Mirna VÃ¡zquez Rosas-Landa, David Alberto GarcÃ\xada-Estrada',
 'date': 'Oct 28 - Oct 31, 2024'}</code></pre>
</div>
<p>This was just for one row, but we can iterate over all the rows in
the table adding a for loop and appending each dictionary to a list.
That list will be transformed to a Pandas dataframe so we can see the
results nicely.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>list_of_workshops <span class="op">=</span> []</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> <span class="bu">range</span>(num_workshops):</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>	n_row <span class="op">=</span> workshops_table.contents[row]</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>	first_cell <span class="op">=</span> n_row.contents[<span class="dv">0</span>]</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>	second_cell <span class="op">=</span> first_cell.next_sibling</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>	third_cell <span class="op">=</span> second_cell.next_sibling</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>	dict_w <span class="op">=</span> {}</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>	dict_w[<span class="st">'type'</span>] <span class="op">=</span> first_cell.find(<span class="st">'img'</span>)[<span class="st">'title'</span>]</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>	dict_w[<span class="st">'country'</span>] <span class="op">=</span> second_cell.find(<span class="st">'img'</span>)[<span class="st">'title'</span>]</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>	dict_w[<span class="st">'link'</span>] <span class="op">=</span> second_cell.find(<span class="st">'a'</span>)[<span class="st">'href'</span>]</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>	dict_w[<span class="st">'host'</span>] <span class="op">=</span> second_cell.find(<span class="st">'a'</span>).get_text()</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a>	dict_w[<span class="st">'all_text'</span>] <span class="op">=</span> second_cell.get_text(strip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a>	dict_w[<span class="st">'date'</span>] <span class="op">=</span> third_cell.get_text(strip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a>	list_of_workshops.append(dict_w)</span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a>result_df <span class="op">=</span> pd.DataFrame(list_of_workshops)</span></code></pre>
</div>
<p>Great! We’ve finished our first scraping task on a real website.
Please be aware that there are multiple ways of achieving the same
result. For example, instead of using the <code>.contents()</code>
method to access the different rows of the table, we could have used
<code>.find_all('tr')</code> to scan the table and loop through the row
elements. Similarly, instead of moving to the siblings of the first data
cell, we could have used <code>.find_all('td')</code>. Code using that
other approach would look like this. Remember, the results are the
same!</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>list_of_workshops <span class="op">=</span> []</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> workshops_table.find_all(<span class="st">'tr'</span>):</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>	cells <span class="op">=</span> row.find_all(<span class="st">'td'</span>)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>	first_cell <span class="op">=</span> cells[<span class="dv">0</span>]</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>	second_cell <span class="op">=</span> cells[<span class="dv">1</span>]</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>	third_cell <span class="op">=</span> cells[<span class="dv">2</span>]</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>	dict_w <span class="op">=</span> {}</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>	dict_w[<span class="st">'type'</span>] <span class="op">=</span> first_cell.find(<span class="st">'img'</span>)[<span class="st">'title'</span>]</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>	dict_w[<span class="st">'country'</span>] <span class="op">=</span> second_cell.find(<span class="st">'img'</span>)[<span class="st">'title'</span>]</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a>	dict_w[<span class="st">'link'</span>] <span class="op">=</span> second_cell.find(<span class="st">'a'</span>)[<span class="st">'href'</span>]</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>	dict_w[<span class="st">'host'</span>] <span class="op">=</span> second_cell.find(<span class="st">'a'</span>).get_text()</span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>	dict_w[<span class="st">'all_text'</span>] <span class="op">=</span> second_cell.get_text(strip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a>	dict_w[<span class="st">'date'</span>] <span class="op">=</span> third_cell.get_text(strip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a>	list_of_workshops.append(dict_w)</span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a>upcomingworkshops_df <span class="op">=</span> pd.DataFrame(list_of_workshops)</span></code></pre>
</div>
<p>A key takeaway from this exercise is that, when we want to scrape
data in a structured way, we have to spend some time getting to know how
the website is structured and how we can identify and extract only the
elements we are interested in.</p>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Extract the same information as in the previous exercise, but this
time from the Past Workshops Page at <a href="https://carpentries.org/past_workshops/" class="external-link">https://carpentries.org/past_workshops/</a>.
Which 5 countries have held the most workshops, and how many has each
held?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>We can reuse directly the code we wrote before, changing only the URL
we got the HTML from.</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>url <span class="op">=</span> <span class="st">'https://carpentries.org/past_workshops/'</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>req <span class="op">=</span> requests.get(url).text</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>cleaned_req <span class="op">=</span> re.sub(<span class="vs">r'\s*\n\s*'</span>, <span class="st">''</span>, req).strip()</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(cleaned_req, <span class="st">'html.parser'</span>)</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>workshops_table <span class="op">=</span> soup.find(<span class="st">'table'</span>)</span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a>list_of_workshops <span class="op">=</span> []</span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> workshops_table.find_all(<span class="st">'tr'</span>):</span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a>	cells <span class="op">=</span> row.find_all(<span class="st">'td'</span>)</span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>	first_cell <span class="op">=</span> cells[<span class="dv">0</span>]</span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a>	second_cell <span class="op">=</span> cells[<span class="dv">1</span>]</span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a>	third_cell <span class="op">=</span> cells[<span class="dv">2</span>]</span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a>	dict_w <span class="op">=</span> {}</span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a>	dict_w[<span class="st">'type'</span>] <span class="op">=</span> first_cell.find(<span class="st">'img'</span>)[<span class="st">'title'</span>]</span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a>	dict_w[<span class="st">'country'</span>] <span class="op">=</span> second_cell.find(<span class="st">'img'</span>)[<span class="st">'title'</span>]</span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a>	dict_w[<span class="st">'link'</span>] <span class="op">=</span> second_cell.find(<span class="st">'a'</span>)[<span class="st">'href'</span>]</span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a>	dict_w[<span class="st">'host'</span>] <span class="op">=</span> second_cell.find(<span class="st">'a'</span>).get_text()</span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a>	dict_w[<span class="st">'all_text'</span>] <span class="op">=</span> second_cell.get_text(strip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a>	dict_w[<span class="st">'date'</span>] <span class="op">=</span> third_cell.get_text(strip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a>	list_of_workshops.append(dict_w)</span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" tabindex="-1"></a>pastworkshops_df <span class="op">=</span> pd.DataFrame(list_of_workshops)</span>
<span id="cb17-24"><a href="#cb17-24" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Total number of workshops in the table: '</span>, <span class="bu">len</span>(pastworkshops_df))</span>
<span id="cb17-26"><a href="#cb17-26" tabindex="-1"></a></span>
<span id="cb17-27"><a href="#cb17-27" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Top 5 of countries by number of workshops held: </span><span class="ch">\n</span><span class="st">'</span>,</span>
<span id="cb17-28"><a href="#cb17-28" tabindex="-1"></a>      pastworkshops_df[<span class="st">'location'</span>].value_counts().head())</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Total number of workshops in the table:  3830
Top 5 of countries by number of workshops held:
 country
US    1837
GB     468
AU     334
CA     225
DE     172
Name: count, dtype: int64</code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>For a more challenging exercise, try to add to our output dataframe
if the workshop was held online or not.</p>
<p>You’ll notice from the website that the online workshops have a world
icon next between the country flag and the name of the institution that
hosts the workshop.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>To start, we can see in the HTML document that the world icon is in
the second data cell of a row. Additionally, for those workshops that
are online, there is an additional image element with these attributes
<code>&lt;img title="Online" alt="globe image" class="flags"/&gt;</code>.
So we could search if the second data cell has an element with an
attribute of <code>title="Online"</code>. If it doesn’t, the
<code>.find()</code> method would return nothing, what in Python is
called a “NoneType” data type. So if <code>.find()</code> returns None,
we should fill the respective cell in our dataframe with a “No”, meaning
that the workshop not held online, and in the opposite case fill it with
a “Yes”. Here is a possible code solution, which you would add to the
previous code where we extracted the other data and created the
dataframe.</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="cf">if</span> second_cell.find(title<span class="op">=</span><span class="st">"Online"</span>) <span class="op">==</span> <span class="va">None</span>:</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>  online_value <span class="op">=</span> <span class="st">"No"</span></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>  online_value <span class="op">=</span> <span class="st">"Yes"</span></span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>dict_w[<span class="st">'online'</span>] <span class="op">=</span> online_value</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="automating-data-collection">Automating data collection<a class="anchor" aria-label="anchor" href="#automating-data-collection"></a>
</h2>
<hr class="half-width">
<p>Until now we’ve only scraped one website at a time. But there may be
situations where the information you need will be split in different
pages, or where you have to follow a trace of hyperlinks. With the tools
we’ve learned until now, this new task is straightforward. We would have
to add a loop that goes to those other pages, gets the HTML document
using the <code>requests</code> package, and parses the HTML with
<code>BeautifulSoup</code> to extract the required information.</p>
<p>The additional and important step to consider in this task is to add
a wait time between each request to the website, so we don’t overload
the web server that is providing us the information we need. If we send
too many requests in a short period of time, we can prevent other
“normal” users from accessing the site during that time, or even cause
the server to run out of resources and crash. If the provider of the
website detects an excessive use, it could block our computer from
accessing that website, or even take legal action in extreme cases.</p>
<p>To make sure we don’t crash the server, we can add a wait time
between each step of our loop with the built-in Python module
<code>time</code> and its <code>sleep()</code> function. With this
function, Python will wait for the specified number of seconds before
continuing to execute the next line of code. For example, when you run
the following code, Python will wait 10 seconds between each print
execution.</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> sleep</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'First'</span>)</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>sleep(<span class="dv">10</span>)</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Second'</span>)</span></code></pre>
</div>
<p>Let’s incorporate this important principle for extracting additional
information from each of our workshop websites in the upcoming list. We
already have our <code>upcomingworkshops_df</code> dataframe, and in
there, a <code>link</code> column with the URL to the website for each
individual workshop. For example, let’s make a request for the HTML of
the first workshop in the dataframe, and take a look.</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>first_url <span class="op">=</span> upcomingworkshops_df.loc[<span class="dv">0</span>, <span class="st">'link'</span>]</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"URL we are visiting: "</span>, first_url)</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>req <span class="op">=</span> requests.get(first_url).text</span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a>cleaned_req <span class="op">=</span> re.sub(<span class="vs">r'\s*\n\s*'</span>, <span class="st">''</span>, req).strip()</span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(cleaned_req, <span class="st">'html.parser'</span>)</span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a><span class="bu">print</span>(soup.prettify())</span></code></pre>
</div>
<p>If we explore the HTML this way, or using the ‘View page source’ in
the browser, we notice something interesting in the
<code>&lt;head&gt;</code> element. As this information is inside
<code>&lt;head&gt;</code> instead of the <code>&lt;body&gt;</code>
element, it won’t be displayed in our browser when we visit the page,
but the meta elements will provide metadata for search engines to better
understand, display, and index the page. Each of this
<code>&lt;meta&gt;</code> tags contain useful information for our table
of workshops, for example, a well formatted start and end date, the
exact location of the workshop with latitude and longitude (for those
not online), the language in which it will be taught, and a more
structured way of listing instructors and helpers. Each of these data
points can be identified by the the “name” attribute in the
<code>&lt;meta&gt;</code> tags, and the information we want to extract
is the value in the “content” attribute.</p>
<p>The following code automates the process of getting this data from
each website, for the first five workshops in our
<code>upcomingworkshops_df</code> dataframe. We will only do it for five
workshops to not send too many requests overwhelming the server, but we
could also do it for all the workshops.</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="co"># List of URLs in our dataframe</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>urls <span class="op">=</span> <span class="bu">list</span>(upcomingworkshops_df.loc[:<span class="dv">5</span>, <span class="st">'link'</span>])</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a><span class="co"># Start an empty list to store the different dictionaries with our data</span></span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>list_of_workshops <span class="op">=</span> []</span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a><span class="co"># Start a loop over each URL</span></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a><span class="cf">for</span> item <span class="kw">in</span> tqdm(urls):</span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a>    <span class="co"># Get the HTML and parse it</span></span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a>    req <span class="op">=</span> requests.get(item).text</span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a>    cleaned_req <span class="op">=</span> re.sub(<span class="vs">r'\s*\n\s*'</span>, <span class="st">''</span>, req).strip()</span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a>    soup <span class="op">=</span> BeautifulSoup(cleaned_req, <span class="st">'html.parser'</span>)</span>
<span id="cb22-13"><a href="#cb22-13" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" tabindex="-1"></a>    <span class="co"># Start an empty dictionary and fill it with the URL, which</span></span>
<span id="cb22-15"><a href="#cb22-15" tabindex="-1"></a>    <span class="co"># is our identifier with our other dataframe</span></span>
<span id="cb22-16"><a href="#cb22-16" tabindex="-1"></a>    dict_w <span class="op">=</span> {}</span>
<span id="cb22-17"><a href="#cb22-17" tabindex="-1"></a>    dict_w[<span class="st">'link'</span>] <span class="op">=</span> item</span>
<span id="cb22-18"><a href="#cb22-18" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" tabindex="-1"></a>    <span class="co"># Use the find function to search for the &lt;meta&gt; tag that </span></span>
<span id="cb22-20"><a href="#cb22-20" tabindex="-1"></a>    <span class="co"># has each specific 'name' attribute and get the value in the</span></span>
<span id="cb22-21"><a href="#cb22-21" tabindex="-1"></a>    <span class="co"># 'content' attribute</span></span>
<span id="cb22-22"><a href="#cb22-22" tabindex="-1"></a>    dict_w[<span class="st">'startdate'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'startdate'</span>})[<span class="st">'content'</span>]</span>
<span id="cb22-23"><a href="#cb22-23" tabindex="-1"></a>    dict_w[<span class="st">'enddate'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'enddate'</span>})[<span class="st">'content'</span>]</span>
<span id="cb22-24"><a href="#cb22-24" tabindex="-1"></a>    dict_w[<span class="st">'language'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'language'</span>})[<span class="st">'content'</span>]</span>
<span id="cb22-25"><a href="#cb22-25" tabindex="-1"></a>    dict_w[<span class="st">'latlng'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'latlng'</span>})[<span class="st">'content'</span>]</span>
<span id="cb22-26"><a href="#cb22-26" tabindex="-1"></a>    dict_w[<span class="st">'instructor'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'instructor'</span>})[<span class="st">'content'</span>]</span>
<span id="cb22-27"><a href="#cb22-27" tabindex="-1"></a>    dict_w[<span class="st">'helper'</span>] <span class="op">=</span> soup.find(<span class="st">'meta'</span>, attrs <span class="op">=</span> {<span class="st">'name'</span>: <span class="st">'helper'</span>})[<span class="st">'content'</span>]</span>
<span id="cb22-28"><a href="#cb22-28" tabindex="-1"></a></span>
<span id="cb22-29"><a href="#cb22-29" tabindex="-1"></a>    <span class="co"># Append to our list</span></span>
<span id="cb22-30"><a href="#cb22-30" tabindex="-1"></a>    list_of_workshops.append(dict_w)</span>
<span id="cb22-31"><a href="#cb22-31" tabindex="-1"></a></span>
<span id="cb22-32"><a href="#cb22-32" tabindex="-1"></a>    <span class="co"># Be respectful, wait at least 3 seconds before a new request</span></span>
<span id="cb22-33"><a href="#cb22-33" tabindex="-1"></a>    sleep(<span class="dv">3</span>)</span>
<span id="cb22-34"><a href="#cb22-34" tabindex="-1"></a></span>
<span id="cb22-35"><a href="#cb22-35" tabindex="-1"></a>extradata_upcoming_df <span class="op">=</span> pd.DataFrame(list_of_workshops)</span></code></pre>
</div>
<div id="challenge3" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>It is possible that you received an error when executing the previous
block code, and the most probable reason is that the URL your tried to
visit didn’t exist. This is known as 404 code error, that indicates the
requested page doesn’t exist, or more precisely, it cannot be found on
the server. What would be your approach to work around this possible
error?</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" aria-labelledby="headingSolution3" data-bs-parent="#accordionSolution3">
<div class="accordion-body">
<p>A Pythonic crude way of working around any error for a given URL
would be to use a <a href="https://docs.python.org/3/tutorial/errors.html" class="external-link">try and except
block</a>, for which you would ignore any URL that throws an error and
continue with the next one.</p>
<p>A more stylish way to deal when a web page doesn’t exist is to get
the actual response code when <code>requests</code> tries to reach the
page. If you receive a 200 code, it means the request was successful. In
any other case, you’d want to store the code and skip the scraping of
that page. The code you’d use to get the response code is:</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>req <span class="op">=</span> requests.get(url)</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="bu">print</span>(req.status_code)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>We can get the HTML behind any website using the “requests” package
and the function <code>requests.get('website_url').text</code>.</li>
<li>An HTML document is a nested tree of elements. Therefore, from a
given element, we can access its child, parent, or sibling, using
<code>.contents</code>, <code>.parent</code>,
<code>.next_sibling</code>, and <code>previous_sibling</code>.</li>
<li>It’s polite to not send too many requests to a website in a short
period of time. For that, we can use the <code>sleep()</code> function
of the built-in Python module <code>time</code>.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-dynamic-websites"><p>Content from <a href="dynamic-websites.html">Dynamic websites</a></p>
<hr>
<p>Last updated on 2024-11-04 |

        <a href="https://github.com/josenino95/web-scraping-python/edit/main/episodes/dynamic-websites.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What are the differences between static and dynamic websites?</li>
<li>Why is it important to understand these differences when doing web
scraping?</li>
<li>How can I start my own web scraping project?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Use the <code>Selenium</code> package to scrape dynamic
websites.</li>
<li>Identify the elements of interest using the browser’s “Inspect”
tool.</li>
<li>Understand the usual pipeline of a web scraping project.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="you-see-it-but-the-html-doesnt-have-it">You see it but the HTML doesn’t have it!<a class="anchor" aria-label="anchor" href="#you-see-it-but-the-html-doesnt-have-it"></a>
</h2>
<hr class="half-width">
<p>Visit the following webpage created by Hartley Brody for the purpose
of learning and practicing web scraping: <a href="https://www.scrapethissite.com/pages/ajax-javascript/" class="external-link">https://www.scrapethissite.com/pages/ajax-javascript/</a>
(read first the <a href="https://www.scrapethissite.com/faq/" class="external-link">terms of
use</a>). Select “2015” to see that year’s Oscar winning films. Now look
at the HTML behind it as we’ve learned, using the “View page source”
tool on your browser or in Python using the requests and BeautifulSoup
packages. Can you find in any place of the HTML the best picture winner
“Spotlight”? Can you find any other of the movies or the data from the
table? If you can’t, how could you scrape this page?</p>
<p>When you explore a page like this, you’ll notice that the movie data,
including the title “Spotlight,” isn’t actually in the initial HTML
source. This is because the website uses JavaScript to load the
information dynamically. JavaScript is a programming language that runs
in your browser, allowing websites to fetch, process, and display
content on the fly, often based on user actions like clicking a button.
When you select “2015”, the browser executes JavaScript (called by one
of the <code>&lt;script&gt;</code> elements you see in the HTML) to
retrieve the relevant movie information from the web server and build a
new HTML document with actual information in the table. This makes the
page feel more interactive, but it also means the initial HTML you see
doesn’t contain the movie data itself.</p>
<p>Let’s explore a new way to view HTML elements in your browser to
better understand the differences in an HTML document before and after
JavaScript is executed. On the Oscar winners page you just visited,
right-click (or Control key + Click on Mac) and select “Inspect” from
the pop-up menu, as shown in the image below. This opens DevTools on the
side of your browser, offering a range of features for inspecting,
debugging, and analyzing web pages in real-time. For this workshop,
however, we’ll focus on just the “Elements” tab. In the “Elements” tab,
you’ll see an HTML document that actually includes the table element,
unlike what you saw in “View Page Source”. This difference is because
“View Page Source” displays the original HTML, before any JavaScript is
run, while “Inspect” reveals the HTML as it appears after JavaScript has
executed.</p>
<figure><img src="fig/inspect.png" alt="A screenshot of Google Chrome web browser, showing how to use Inspect from the Chrome DevTools" class="figure mx-auto d-block"></figure><p>As the <code>requests</code> package retrieves the source HTML, we
need a different approach to scrape these types of websites. For this,
we will use the <code>Selenium</code> package. But don’t forget about
the “Inspect” tool we just learned, it will be handy when scraping.</p>
</section><section><h2 class="section-heading" id="using-selenium-to-scrape-dynamic-websites">Using Selenium to scrape dynamic websites<a class="anchor" aria-label="anchor" href="#using-selenium-to-scrape-dynamic-websites"></a>
</h2>
<hr class="half-width">
<p><a href="https://www.selenium.dev/" class="external-link">Selenium</a> is an open source
project for web browser automation. It will be useful for our scraping
tasks as it will act as a real user interacting with a webpage in a
browser. This way, Selenium will render pages in a browser environment,
allowing JavaScript to load dynamic content, and therefore giving us
access to the website HTML after JavaScript has executed. Additionally,
this package simulates real user interactions like filling in text
boxes, clicking, scrolling, or selecting drop-down menus, which will be
useful when we scrape dynamic websites.</p>
<p>To use it, we’ll load “webdriver” and “By” from the
<code>selenium</code> package. webdriver open or simulate a web browser,
interacting with it based on the instructions we give. By will allow us
to specify how we will select a given element in the HTML, by tag (using
“By.TAG_NAME”) or by attributes like class (“By.CLASS_NAME”), id
(“By.ID”), or name (“By.NAME”). We will also load the other packages we
used in the previous episode.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> sleep</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> selenium <span class="im">import</span> webdriver</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.common.by <span class="im">import</span> By</span></code></pre>
</div>
<p>Selenium can simulate multiple multiple browsers like Chrome,
Firefox, Safari, etc. For now, we’ll use Chrome. When you run the
following line of code, you’ll notice that a Google Chrome window opens
up. Don’t close it, as this is how Selenium interacts with the browser.
Later we’ll see how to do <em>headless</em> browser interactions,
headless meaning that browser interactions will happen in the
background, without opening a new browser window or user interface.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome()</span></code></pre>
</div>
<p>Now, to tell the browser to visit our Oscar winners page, use the
<code>.get()</code> method on the <code>driver</code> object we just
created.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>driver.get(<span class="st">"https://www.scrapethissite.com/pages/ajax-javascript/"</span>)</span></code></pre>
</div>
<p>How can we direct Selenium to click the text “2015” for the table of
that year tho show up? First, we need to find that element, in a similar
way to how we find elements with BeautifulSoup. Just like we used
<code>.find()</code> in BeautifulSoup to find the first element that
matched the specified criteria, in Selenium we have
<code>.find_element()</code>. Likewise, as we used
<code>.find_all()</code> in BeautifulSoup to return a list of all
coincidences for our search criteria, we can use
<code>.find_elements()</code> in Selenium. But the syntax of how we
specify the search paramenters will be a little different.</p>
<p>If we wanted to search a table element that has the
<code>&lt;table&gt;</code> tag, we would run
<code>driver.find_element(by=By.TAG_NAME, value="table")</code>. If we
wanted to search an element with a specific value in the “class”
attribute, for example an element like
<code>&lt;tr class="film"&gt;</code> we would run
<code>driver.find_element(by=By.CLASS_NAME, value="film")</code>. To
know what element we need to click to open “2015” table of Oscar winners
we can use the “Inspect” tool (remember you can do this in Google Chrome
by pointing your mouse over the “2015” value, make a right-click, and
select “Inspect” from the pop-up menu). In the DevTools window, you’ll
see element
<code>&lt;a href="#" class="year-link" id="2015"&gt;2015&lt;/a&gt;</code>.
As the ID attribute is unique for only one element in the HTML, we can
directly select the element by this attribute using the code you’ll find
after the following image.</p>
<figure><img src="fig/inspect_element.PNG" alt="A screenshot of Google Chrome web browser, showing how to search a specific element by using Inspect from the Chrome DevTools" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>button_2015 <span class="op">=</span> driver.find_element(by<span class="op">=</span>By.ID, value<span class="op">=</span><span class="st">"2015"</span>)</span></code></pre>
</div>
<p>We’ve located the hyperlink element we want to click to get the table
for that year, and on that element we will use the <code>.click()</code>
method to interact with it. As the table takes a couple of seconds to
load, we will also use the <code>sleep()</code> function from the “time”
module to wait will the JavaScript runs and the table loads. Then, we
use <code>driver.page_source</code> for Selenium to get the HTML
document from the website, and we store it in a variable called
<code>html_2015</code>. Finally, we close the web browser that Selenium
was using with <code>driver.quit()</code>.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>button_2015.click()</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>sleep(<span class="dv">3</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>html_2015 <span class="op">=</span> driver.page_source</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>driver.quit()</span></code></pre>
</div>
<p>Importantly, the HTML document we stored in <code>html_2015</code>
<strong>is the HTML after the dynamic content loaded</strong>, so it
will contain the table values for 2015 that weren’t there originally and
that we wouldn’t be able to see if we had used the <code>requests</code>
package instead.</p>
<p>We could continue using Selenium and its <code>.find_element()</code>
and <code>.find_elements()</code> methods to to extract our data of
interest. But instead, we will use BeautifulSoup to parse the HTML and
find elements, as we already have some practice using it. If we search
for the first element with class attribute equal to “film-title” and
return the text inside it, we see that this HTML has the “Spotlight”
movie.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(html_2015, <span class="st">'html.parser'</span>)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="bu">print</span>(soup.find(class_<span class="op">=</span><span class="st">'film'</span>).prettify())</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="op">&lt;</span>tr <span class="kw">class</span><span class="op">=</span><span class="st">"film"</span><span class="op">&gt;</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a> <span class="op">&lt;</span>td <span class="kw">class</span><span class="op">=</span><span class="st">"film-title"</span><span class="op">&gt;</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>  Spotlight</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a> <span class="op">&lt;/</span>td<span class="op">&gt;</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a> <span class="op">&lt;</span>td <span class="kw">class</span><span class="op">=</span><span class="st">"film-nominations"</span><span class="op">&gt;</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>  <span class="dv">6</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a> <span class="op">&lt;/</span>td<span class="op">&gt;</span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a> <span class="op">&lt;</span>td <span class="kw">class</span><span class="op">=</span><span class="st">"film-awards"</span><span class="op">&gt;</span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>  <span class="dv">2</span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a> <span class="op">&lt;/</span>td<span class="op">&gt;</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a> <span class="op">&lt;</span>td <span class="kw">class</span><span class="op">=</span><span class="st">"film-best-picture"</span><span class="op">&gt;</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>  <span class="op">&lt;</span>i <span class="kw">class</span><span class="op">=</span><span class="st">"glyphicon glyphicon-flag"</span><span class="op">&gt;</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>  <span class="op">&lt;/</span>i<span class="op">&gt;</span></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a> <span class="op">&lt;/</span>td<span class="op">&gt;</span></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="op">&lt;/</span>tr<span class="op">&gt;</span></span></code></pre>
</div>
<p>The following code repeats the process of clicking and loading the
2015 data, but now using “headless” mode (i.e. without opening a browser
window). Then, it extracts data from the table one column at a time,
taking advantage that each column has a unique class attribute that
identifies it. Instead of using for loops to extract data from each
element that <code>.find_all()</code> finds, we use list comprehensions.
You can learn more about them reading <a href="https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions" class="external-link">Python’s
documentation for list comprehensions</a>, or with this <a href="https://www.programiz.com/python-programming/list-comprehension" class="external-link">Programiz
short tutorial</a>.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Create the Selenium webdriver and make it headless</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>options <span class="op">=</span> ChromeOptions()</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>options.add_argument(<span class="st">"--headless=new"</span>)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome(options<span class="op">=</span>options)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co"># Load the website. Find and click 2015. Get post JavaScript execution HTML. Close webdriver</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>driver.get(<span class="st">"https://www.scrapethissite.com/pages/ajax-javascript/"</span>)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>button_2015 <span class="op">=</span> driver.find_element(by<span class="op">=</span>By.ID, value<span class="op">=</span><span class="st">"2015"</span>)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>button_2015.click()</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>sleep(<span class="dv">3</span>)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>html_2015 <span class="op">=</span> driver.page_source</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>driver.quit()</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="co"># Parse HTML using BeautifulSoup and extract each column as a list of values ising list comprehensions</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(html_2015, <span class="st">'html.parser'</span>)</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>titles_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-title"</span>)]</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>nominations_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-nominations"</span>)]</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>awards_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-awards"</span>)]</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a><span class="co"># For the best picture column, we can't use .get_text() as there is no text</span></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a><span class="co"># Rather, we want to see if there is an &lt;i&gt; tag</span></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>best_picture_lc <span class="op">=</span> [<span class="st">"Yes"</span> <span class="cf">if</span> elem.find(<span class="st">"i"</span>) <span class="op">==</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">"No"</span> <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-best-picture"</span>)]</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a><span class="co"># Create a dataframe based on the previous lists</span></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>movies_2015 <span class="op">=</span> pd.DataFrame(</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>    {<span class="st">'titles'</span>: titles_lc, <span class="st">'nominations'</span>: nominations_lc, <span class="st">'awards'</span>: awards_lc, <span class="st">'best_picture'</span>: best_picture_lc}</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>)</span></code></pre>
</div>
<div id="challenge1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>Based on what we’ve learned in this episode, write code for getting
the data of all the years from 2010 to 2015 of <a href="https://www.scrapethissite.com/pages/ajax-javascript/" class="external-link">Hartley
Brody’s website</a> with information of Oscar Winning Films. Hint:
You’ll use the same code, but add loop through each year.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>Besides adding a loop for each year, the following solution is
refactoring the code by creating two functions: one that finds and
clicks a year returning the html after the data shows up, and another
that gets the html and parses it to extract the data and create a
dataframe.</p>
<p>So you can see the process of how Selenium opens the browser and
clicks the years, we are not adding the “headless” option.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Function to search year hyperlink and click it</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="kw">def</span> findyear_click_gethtml(year):</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>    button <span class="op">=</span> driver.find_element(by<span class="op">=</span>By.ID, value<span class="op">=</span>year)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>    button.click()</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    sleep(<span class="dv">3</span>)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>    html <span class="op">=</span> driver.page_source</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>    <span class="cf">return</span> html</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="co"># Function to parse html, extract table data, and assign year column</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a><span class="kw">def</span> parsehtml_extractdata(html, year):</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>    soup <span class="op">=</span> BeautifulSoup(html, <span class="st">'html.parser'</span>)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>    titles_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-title"</span>)]</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>    nominations_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-nominations"</span>)]</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>    awards_lc <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-awards"</span>)]</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>    best_picture_lc <span class="op">=</span> [<span class="st">"No"</span> <span class="cf">if</span> elem.find(<span class="st">"i"</span>) <span class="op">==</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">"Yes"</span> <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(class_<span class="op">=</span><span class="st">"film-best-picture"</span>)]</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>    movies_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>        {<span class="st">'titles'</span>: titles_lc, <span class="st">'nominations'</span>: nominations_lc, <span class="st">'awards'</span>: awards_lc, <span class="st">'best_picture'</span>: best_picture_lc, <span class="st">'year'</span>: year}</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>    )</span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>    <span class="cf">return</span> movies_df</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a><span class="co"># Open Selenium webdriver and go to the page</span></span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome()</span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>driver.get(<span class="st">"https://www.scrapethissite.com/pages/ajax-javascript/"</span>)</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a><span class="co"># Create empty dataframe where we will append/concatenate the dataframes we get for each year</span></span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a>result_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a><span class="cf">for</span> year <span class="kw">in</span> [<span class="st">"2010"</span>, <span class="st">"2011"</span>, <span class="st">"2012"</span>, <span class="st">"2013"</span>, <span class="st">"2014"</span>, <span class="st">"2015"</span>]:</span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a>    html_year <span class="op">=</span> findyear_click_gethtml(year)</span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a>    df_year <span class="op">=</span> parsehtml_extractdata(html_year, year)</span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a>    result_df <span class="op">=</span> pd.concat([result_df, df_year])</span>
<span id="cb9-32"><a href="#cb9-32" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" tabindex="-1"></a><span class="co"># Close the browser that Selenium opened</span></span>
<span id="cb9-34"><a href="#cb9-34" tabindex="-1"></a>driver.quit()</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p>If you are tired of scraping table data like we’ve been doing for the
last two episodes, here is another dynamic website exercise where you
can practice what you’ve learned. Go to <a href="https://www.scrapingcourse.com/javascript-rendering" class="external-link">this product
page</a> created by scrapingcourse.com and extract all product names and
prices, and also the hyperlink that each product card has to a detailed
view page.</p>
<p>When you complete that, and if you are up to an additional challenge,
scrape from the detailed view page of each product its SKU, Category and
Description.</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<p>To identify what elements containt the data you need, you should use
the “Inspect” tool in your browser. The following image is a screenshot
of the website. In there we can see that each product card is a
<code>&lt;div&gt;</code> element with multiple attributes that we can
use to narrow down our search to the specific elements we want. For
example, we would use <code>'data-testid'='product-item'</code>. After
we find all <em>divs</em> that satisfy that condition, we can extract
from each the hyperlink, the name, and the price. The hyperlink is the
‘href’ attribute of the <code>&lt;a&gt;</code> tag. The name and price
are inside <code>&lt;span&gt;</code> tags, and we could use multiple
attributes to get each of them. In the following code, we will use
<code>'class'='product-name'</code> to get the name and
<code>'data-content'='product-price'</code> to get the price.</p>
<figure><img src="fig/product_cards_challenge.PNG" alt="A screenshot of Google Chrome web browser, highlighting the `&lt;div&gt;` element that contains the data we want about the product" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Open Selenium webdriver in headless mode and go to the desired page</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>options <span class="op">=</span> webdriver.ChromeOptions()</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>options.add_argument(<span class="st">"--headless=new"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome(options<span class="op">=</span>options)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>driver.get(<span class="st">"https://www.scrapingcourse.com/javascript-rendering"</span>)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co"># As we don't have to click anything, just wait for the JavaScript to load, we can get the HTML right away</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>sleep(<span class="dv">3</span>)</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>html <span class="op">=</span> driver.page_source</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co"># Parste the HTML</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(html, <span class="st">'html.parser'</span>)</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a><span class="co"># Find all &lt;div&gt; elements that have a 'data-testid' attribute with the value of 'product-item'</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>divs <span class="op">=</span> soup.find_all(<span class="st">"div"</span>, attrs <span class="op">=</span> {<span class="st">'data-testid'</span>: <span class="st">'product-item'</span>})</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a><span class="co"># Loop through the &lt;div&gt; elements we found, and for each get the href,</span></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a><span class="co"># the name (inside a &lt;span&gt; element with attribute class="product-name")</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a><span class="co"># and the price (inside a &lt;span&gt; element with attribute data-content="product-price"</span></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>list_of_dicts <span class="op">=</span> []</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a><span class="cf">for</span> div <span class="kw">in</span> divs:</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>    <span class="co"># Create a dictionary to store the data we want for each product</span></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>    item_dict <span class="op">=</span> {</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>        <span class="st">'link'</span>: div.find(<span class="st">'a'</span>)[<span class="st">'href'</span>],</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>        <span class="st">'name'</span>: div.find(<span class="st">'span'</span>, attrs <span class="op">=</span> {<span class="st">'class'</span>: <span class="st">'product-name'</span>}).get_text(),</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>        <span class="st">'price'</span>: div.find(<span class="st">'span'</span>, attrs <span class="op">=</span> {<span class="st">'data-content'</span>: <span class="st">'product-price'</span>}).get_text()</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>    }</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>    list_of_dicts.append(item_dict)</span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>all_products <span class="op">=</span> pd.DataFrame(list_of_dicts)</span></code></pre>
</div>
<p>We could arrive to the same result if we replace the for loop with
list comprehensions. So here is another possible solution with that
approach.</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>links <span class="op">=</span> [elem[<span class="st">'href'</span>] <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(<span class="st">'a'</span>, attrs <span class="op">=</span> {<span class="st">'class'</span>: <span class="st">'product-link'</span>})]</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>names <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(<span class="st">'span'</span>, attrs <span class="op">=</span> {<span class="st">'class'</span>: <span class="st">'product-name'</span>})]</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>prices <span class="op">=</span> [elem.get_text() <span class="cf">for</span> elem <span class="kw">in</span> soup.find_all(<span class="st">'span'</span>, attrs <span class="op">=</span> {<span class="st">'data-content'</span>: <span class="st">'product-price'</span>})]</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>all_products_v2 <span class="op">=</span> pd.DataFrame(</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>    {<span class="st">'link'</span>: links, <span class="st">'name'</span>: names, <span class="st">'price'</span>: prices}</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="the-scraping-pipeline">The scraping pipeline<a class="anchor" aria-label="anchor" href="#the-scraping-pipeline"></a>
</h2>
<hr class="half-width">
<p>By now, you’ve learned about the core tools for web scraping:
requests, BeautifulSoup, and Selenium. These three tools form a
versatile pipeline for almost any web scraping task. When starting a new
scraping project, there are several important steps to follow that will
help ensure you capture the data you need.</p>
<p>The first step is <strong>understanding the website
structure</strong>. Every website is different and structures data in
its own particular way. Spend some time exploring the site and
identifying the HTML elements that contain the information you want.
Next, <strong>determine if the content is static or dynamic</strong>.
Static content can be directly accessed from the HTML source code using
requests and BeautifulSoup, while dynamic content often requires
Selenium to load JavaScript on the page before BeautifulSoup can parse
it.</p>
<p>Once you know how the website presents its data, <strong>start
building your pipeline</strong>. If the content is static, make a
<code>requests</code> call to get the HTML document, and use
<code>BeautifulSoup</code> to locate and extract the necessary elements.
If the content is dynamic, use <code>Selenium</code> to load the page
fully, perform any interactions (like clicking or scrolling), and then
pass the rendered HTML to <code>BeautifulSoup</code> for parsing and
extracing the necessary elements. Finally, <strong>format and store the
data</strong> in a structured way that’s useful for your specific
project and that makes it easy to analyse later.</p>
<p>This scraping pipeline helps break down complex scraping tasks into
manageable steps and allows you to adapt the tools based on the
website’s unique features. With practice, you’ll be able to efficiently
combine these tools to extract valuable data from almost any
website.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Dynamic websites load content using JavaScript, which isn’t present
in the initial or source HTML. It’s important to distinguish between
static and dynamic content when planning your scraping approach.</li>
<li>The <code>Selenium</code> package and its <code>webdriver</code>
module simulate a real user interacting with a browser, allowing it to
execute JavaScript and clicking, scrolling or filling in text
boxes.</li>
<li>Here are the commandand we learned when we use
<code>Selenium</code>:
<ul>
<li>
<code>webdriver.Chrome()</code> # Start the Google Chrome browser
simulator</li>
<li>
<code>.get("website_url")</code> # Go to a given website</li>
<li>
<code>.find_element(by, value)</code> and
<code>.find_elements(by, value)</code> # Get a given element</li>
<li>
<code>.click()</code> # Click the element selected</li>
<li>
<code>.page_source</code> # Get the HTML after JavaScript has
executed, which can later be parsed with BeautifulSoup</li>
<li>
<code>.quit()</code> # Close the browser simulator</li>
</ul>
</li>
<li>The browser’s “Inspect” tool allows users to view the HTML document
after dynamic content has loaded, revealing elements added by
JavaScript. This tool helps identify the specific elements you are
interested in scraping.</li>
<li>A typical scraping pipeline involves understanding the website’s
structure, determining content type (static or dynamic), using the
appropriate tools (requests and BeautifulSoup for static, Selenium and
BeautifulSoup for dynamic), and structuring the scraped data for
analysis.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/josenino95/web-scraping-python/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/josenino95/web-scraping-python/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/josenino95/web-scraping-python/" class="external-link">Source</a></p>
				<p><a href="https://github.com/josenino95/web-scraping-python/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:jose_nino@ucsb.edu">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.10" class="external-link">sandpaper (0.16.10)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.7" class="external-link">pegboard (0.7.7)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.5" class="external-link">varnish (1.0.5)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://josenino95.github.io/web-scraping-python/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "web scraping, data, python, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://josenino95.github.io/web-scraping-python/aio.html",
  "identifier": "https://josenino95.github.io/web-scraping-python/aio.html",
  "dateCreated": "2024-09-23",
  "dateModified": "2024-11-26",
  "datePublished": "2024-11-26"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

